# Word_embeddings_BBC_News_archive
   The BBC news archive contains about 2225 articles with their categories. The stopwords from the sentences are removed and tokenized using the tensorflow library's Tokenizer and the sequence is padded and split into train and test and the neural net is fed with the training sentences and labels and still needs hyperparameter tuning to be done.
